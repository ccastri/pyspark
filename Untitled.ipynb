{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c097a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: findspark in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70d5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd708c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc24c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9d74e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         name  age  risk\n",
      "0      Pilar   53     1\n",
      "1  Francisco   60     2\n",
      "2  Sebastian   28     3\n",
      "3     Camilo   25     4\n",
      "4     Camilo   25     5>\n",
      "             age      risk\n",
      "count   5.000000  5.000000\n",
      "mean   38.200000  3.000000\n",
      "std    16.932218  1.581139\n",
      "min    25.000000  1.000000\n",
      "25%    25.000000  2.000000\n",
      "50%    28.000000  3.000000\n",
      "75%    53.000000  4.000000\n",
      "max    60.000000  5.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test1.csv\")\n",
    "print(df.info)\n",
    "print(df.describe()) #This is a cool one dude!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4354e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('first_app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca5a8201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Castri:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>first_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22c4a201370>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4010aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4be3fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_c0: string, _c1: string, _c2: string]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    5 non-null      object\n",
      " 1   age     5 non-null      int64 \n",
      " 2   risk    5 non-null      int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(df_pyspark)\n",
    "# type(df_pyspark)\n",
    "df.info() # pandas version of schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab8861",
   "metadata": {},
   "source": [
    "print(spark.read.option('header', 'true').csv('test1.csv')) #to make 1st raw the headers\n",
    "df_pyspark = spark.read.option('header', 'true').csv('test1.csv') #look at the dif types\n",
    "print(type(df_pyspark))\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee46eb1",
   "metadata": {},
   "source": [
    "## 2nd dive into pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "566bff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[name: string, age: string, risk: string]\n",
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to have the correct columntype \n",
    "df_2 = spark.read.option('header', 'true').csv('test1.csv', inferSchema = True) \n",
    "print(spark.read.option('header', 'true').csv('test1.csv')) #check types in schema\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7762974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- risk: integer (nullable = true)\n",
      "\n",
      "None\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    " #Checking the types and the Schema\n",
    "print(df_2.printSchema())\n",
    "print(type(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4567ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Pilar', age=53, risk=1),\n",
       " Row(name='Francisco', age=60, risk=2),\n",
       " Row(name='Sebastian', age=28, risk=3)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f37b4490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c995aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|     name|risk|\n",
      "+---------+----+\n",
      "|    Pilar|   1|\n",
      "|Francisco|   2|\n",
      "|Sebastian|   3|\n",
      "|   Camilo|   4|\n",
      "|   Camilo|   5|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type(df_2.select('name')) #to check the data type on the column (pyspark.sql.dataframe.DataFrame)\n",
    "df_2.select(['name', 'risk']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c697881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With pandas it'll go like this:\n",
    "df_2['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a3816df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('risk', 'int')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da24e151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+------------------+\n",
      "|summary|     name|              age|              risk|\n",
      "+-------+---------+-----------------+------------------+\n",
      "|  count|        5|                5|                 5|\n",
      "|   mean|     null|             38.2|               3.0|\n",
      "| stddev|     null|16.93221781102523|1.5811388300841898|\n",
      "|    min|   Camilo|               25|                 1|\n",
      "|    max|Sebastian|               60|                 5|\n",
      "+-------+---------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a259bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[name: string, age: int, risk: int, age after two years: int]\n",
      "+---------+---+----+-------------------+\n",
      "|     name|age|risk|age after two years|\n",
      "+---------+---+----+-------------------+\n",
      "|    Pilar| 53|   1|                 55|\n",
      "|Francisco| 60|   2|                 62|\n",
      "|Sebastian| 28|   3|                 30|\n",
      "|   Camilo| 25|   4|                 27|\n",
      "|   Camilo| 25|   5|                 27|\n",
      "+---------+---+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_2.withColumn('age after two years', df_2['age']+2))#NOT INPLACE must be assigned\n",
    "df_2 = df_2.withColumn('age after two years', df_2['age']+2)\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc5070c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.drop('age after two years')\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0423121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     Name|Age|Risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Rename the columns\n",
    "df_2.withColumnRenamed('name', 'Name',).withColumnRenamed(\"age\", \"Age\").withColumnRenamed(\"risk\", \"Risk\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17701c5f",
   "metadata": {},
   "source": [
    "# How to handle missing values in pyspark\n",
    "### -Dropping cols\n",
    "### -Dropping rows\n",
    "### -Handling missing values and statistic parameters (mean, mode and median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753ed7a",
   "metadata": {},
   "source": [
    "### Avoiding a imputer function to clean up the missing values (Data inputation from pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32e601f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "|     null|  3|null|\n",
      "|     null|  3|   3|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3 = spark.read.csv('test2.csv', header= True, inferSchema= True)\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df85abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# df_3.na.drop(how=\"any\", thresh=None, subset=None) \n",
    "any, all\n",
    "1,2,3...,n, etc. (the number of null values)\n",
    "subset= for checking specific columns ([\"age\"], [\"name\",\"age\"])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_3.na.drop().show() # To drop all rows with at least 1 null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47e7cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "|     null|  3|   3|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d72b4560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+\n",
      "|     name|age|risk|\n",
      "+---------+---+----+\n",
      "|    Pilar| 53|   1|\n",
      "|Francisco| 60|   2|\n",
      "|Sebastian| 28|   3|\n",
      "|   Camilo| 25|   4|\n",
      "|   Camilo| 25|   5|\n",
      "+---------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3.na.drop(how='any', subset=[\"name\",\"risk\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e6e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
